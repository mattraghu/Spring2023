{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the dataset\n",
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Input Text\n",
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "#Get All Unique Characters\n",
    "chars = sorted(list(set(text)))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 2]\n",
      "Hello!\n"
     ]
    }
   ],
   "source": [
    "#Tokenize the text- This will be used to convert the text to numbers\n",
    "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
    "idx_to_char = {i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "#Encode and Decode Functions for Strings\n",
    "def encode(s):\n",
    "    return [char_to_idx[ch] for ch in s]\n",
    "def decode(l):\n",
    "    return ''.join([idx_to_char[i] for i in l])\n",
    "\n",
    "#Test\n",
    "encodedText = encode(\"Hello!\")\n",
    "print(encodedText)\n",
    "print(decode(encodedText))\n",
    "\n",
    "#Note: This is a very simple tokenization method. There are better ways to do this. Example: Using tiktoken from OpenAI. (Sub-word tokenization = Don't need a new token for every letter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x107d03670>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some Imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of encoded text:  1115394\n",
      "torch.Size([1115394])\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])\n"
     ]
    }
   ],
   "source": [
    "#Encode the input text and store it into a Torch Tensor\n",
    "#A tensor is a multi-dimensional matrix containing elements of a single data type\n",
    "\n",
    "#Convert the text to numbers\n",
    "encodedText = encode(text)\n",
    "print(\"Length of encoded text: \", len(encodedText))\n",
    "\n",
    "#Convert the list to a tensor\n",
    "data = torch.tensor(encodedText, dtype=torch.long)\n",
    "print(data.shape)\n",
    "print(data[:10]) #First 10 elements (First 10 characters in the text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data:  1115394\n",
      "Length of training data:  1003854\n",
      "Length of validation data:  111540\n"
     ]
    }
   ],
   "source": [
    "#Get Training and Validation Data\n",
    "#We will use the first 90% of the data for training and the last 10% for validation\n",
    "\n",
    "#Get the length of the data\n",
    "dataLen = len(data)\n",
    "print(\"Length of data: \", dataLen)\n",
    "\n",
    "#Get the length of the training data  \n",
    "trainLen = int(dataLen * 0.9)\n",
    "\n",
    "#Get the training data\n",
    "train_data = data[:trainLen]\n",
    "print(\"Length of training data: \", len(train_data))\n",
    "\n",
    "#Get the validation data\n",
    "val_data = data[trainLen:]  \n",
    "print(\"Length of validation data: \", len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence:  tensor([18, 47, 56, 57, 58,  1, 15, 47])\n",
      "Output sequence:  tensor([47, 56, 57, 58,  1, 15, 47, 58])\n",
      "1 : Context:  tensor([18])  Target:  tensor(47)\n",
      "2 : Context:  tensor([18, 47])  Target:  tensor(56)\n",
      "3 : Context:  tensor([18, 47, 56])  Target:  tensor(57)\n",
      "4 : Context:  tensor([18, 47, 56, 57])  Target:  tensor(58)\n",
      "5 : Context:  tensor([18, 47, 56, 57, 58])  Target:  tensor(1)\n",
      "6 : Context:  tensor([18, 47, 56, 57, 58,  1])  Target:  tensor(15)\n",
      "7 : Context:  tensor([18, 47, 56, 57, 58,  1, 15])  Target:  tensor(47)\n",
      "8 : Context:  tensor([18, 47, 56, 57, 58,  1, 15, 47])  Target:  tensor(58)\n"
     ]
    }
   ],
   "source": [
    "block_size = 8 #The length of the sequence we want to train on (the context)\n",
    "#Example: If block_size = 8, then we want to predict the 9th character in the sequence\n",
    "#This is why we will need to train the model on sequences of length block_size + 1\n",
    "#In the below code the max value of t+1 is block_size\n",
    "\n",
    "x = train_data[0:block_size] # The input sequence\n",
    "y = train_data[1:block_size+1] # The output sequence\n",
    "\n",
    "print(\"Input sequence: \", x)\n",
    "print(\"Output sequence: \", y)\n",
    "\n",
    "for t in range(block_size): \n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(t+1, ': Context: ', str(context), ' Target: ', str(target)) \n",
    "    #Ex. If data is {1,2,3} and we are given 1, then the target (predicted output) should be 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape:  torch.Size([4, 8])\n",
      "Output batch shape:  torch.Size([4, 8])\n",
      "-----------------\n",
      "Input batch: \n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "-----------------\n",
      "Output batch: \n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "-----------------\n",
      "1 : Context:  tensor([[24],\n",
      "        [44],\n",
      "        [52],\n",
      "        [25]])  Target:  tensor([43, 53, 58, 17])\n",
      "2 : Context:  tensor([[24, 43],\n",
      "        [44, 53],\n",
      "        [52, 58],\n",
      "        [25, 17]])  Target:  tensor([58, 56,  1, 27])\n",
      "3 : Context:  tensor([[24, 43, 58],\n",
      "        [44, 53, 56],\n",
      "        [52, 58,  1],\n",
      "        [25, 17, 27]])  Target:  tensor([ 5,  1, 58, 10])\n",
      "4 : Context:  tensor([[24, 43, 58,  5],\n",
      "        [44, 53, 56,  1],\n",
      "        [52, 58,  1, 58],\n",
      "        [25, 17, 27, 10]])  Target:  tensor([57, 58, 46,  0])\n",
      "5 : Context:  tensor([[24, 43, 58,  5, 57],\n",
      "        [44, 53, 56,  1, 58],\n",
      "        [52, 58,  1, 58, 46],\n",
      "        [25, 17, 27, 10,  0]])  Target:  tensor([ 1, 46, 39, 21])\n",
      "6 : Context:  tensor([[24, 43, 58,  5, 57,  1],\n",
      "        [44, 53, 56,  1, 58, 46],\n",
      "        [52, 58,  1, 58, 46, 39],\n",
      "        [25, 17, 27, 10,  0, 21]])  Target:  tensor([46, 39, 58,  1])\n",
      "7 : Context:  tensor([[24, 43, 58,  5, 57,  1, 46],\n",
      "        [44, 53, 56,  1, 58, 46, 39],\n",
      "        [52, 58,  1, 58, 46, 39, 58],\n",
      "        [25, 17, 27, 10,  0, 21,  1]])  Target:  tensor([43, 58,  1, 54])\n",
      "8 : Context:  tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])  Target:  tensor([39,  1, 46, 39])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337) #Set the seed for reproducibility\n",
    "block_size = 8 #The length of the sequence we want to train on \n",
    "batch_size = 4 #The number of sequences we want to train on at a time\n",
    "\n",
    "def get_batch(split):\n",
    "    #Get the data depending on the split (train or validation)\n",
    "    if split == 'train':\n",
    "        data = train_data\n",
    "    else:\n",
    "        data = val_data\n",
    "    \n",
    "    #Get batch_size random starting indexes\n",
    "    ix = torch.randint(high=len(data)-block_size, size=(batch_size,))\n",
    "\n",
    "    #Construct the input and output sequences\n",
    "    x = [data[i:i+block_size] for i in ix]\n",
    "    y = [data[i+1:i+block_size+1] for i in ix]\n",
    "    \n",
    "    #Convert the sequences to tensors of size (batch_size, block_size)\n",
    "    x = torch.stack(x)\n",
    "    y = torch.stack(y)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "#Test\n",
    "xb, yb = get_batch('train')\n",
    "print(\"Input batch shape: \", xb.shape)\n",
    "print(\"Output batch shape: \", yb.shape)\n",
    "\n",
    "print(\"-----------------\")\n",
    "print(\"Input batch: \")\n",
    "print(xb)\n",
    "print(\"-----------------\")\n",
    "print(\"Output batch: \")\n",
    "print(yb)\n",
    "print(\"-----------------\")\n",
    "\n",
    "for t in range(block_size): #Basically the same as the previous but now we are using batches (multiple sequences)\n",
    "    context = xb[:, :t+1] #Get the first t+1 elements of each sequence\n",
    "    target = yb[:, t]\n",
    "    print(t+1, ': Context: ', str(context), ' Target: ', str(target)) \n",
    "    #Ex. If data is {1,2,3} and we are given 1, then the target (predicted output) should be 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 65])\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        #super() returns the parent object of the class\n",
    "        #In this case, it returns the parent object of BigramLanguageModel which is nn.Module (defined above)\n",
    "        super().__init__() # Call the parent class constructor\n",
    "\n",
    "        \n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size) #Embedding layer\n",
    "        #Embedding layer is used to convert the input tokens to vectors of size embedding_dim\n",
    "        #In this case, the input tokens are numbers (the encoded text) and the embedding_dim is vocab_size\n",
    "        #Vectors will allow us to do math operations on the tokens\n",
    "\n",
    "    def forward(self, idx, targets):\n",
    "\n",
    "        logits = self.token_embedding_table(idx) #Get the embeddings for the input tokensA\n",
    "        return logits\n",
    "\n",
    "m = BigramLanguageModel(len(chars)) #Create the model\n",
    "out = m(xb, yb) #Get the output\n",
    "print(out.shape) #Print the shape of the output\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
