{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the dataset\n",
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Input Text\n",
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "#Get All Unique Characters\n",
    "chars = sorted(list(set(text)))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 2]\n",
      "Hello!\n"
     ]
    }
   ],
   "source": [
    "#Tokenize the text- This will be used to convert the text to numbers\n",
    "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
    "idx_to_char = {i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "#Encode and Decode Functions for Strings\n",
    "def encode(s):\n",
    "    return [char_to_idx[ch] for ch in s]\n",
    "def decode(l):\n",
    "    return ''.join([idx_to_char[i] for i in l])\n",
    "\n",
    "#Test\n",
    "encodedText = encode(\"Hello!\")\n",
    "print(encodedText)\n",
    "print(decode(encodedText))\n",
    "\n",
    "#Note: This is a very simple tokenization method. There are better ways to do this. Example: Using tiktoken from OpenAI. (Sub-word tokenization = Don't need a new token for every letter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1fb6e8b94f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some Imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of encoded text:  1115394\n",
      "torch.Size([1115394])\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "tensor(18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(data[:\u001b[39m10\u001b[39m]) \u001b[39m#First 10 elements (First 10 characters in the text)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#First 10 characters in the text\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[39mprint\u001b[39m(decode(data[:\u001b[39m10\u001b[39;49m]))\n",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(l)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(l):\n\u001b[1;32m----> 9\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([idx_to_char[i] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m l])\n",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(l):\n\u001b[1;32m----> 9\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([idx_to_char[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m l])\n",
      "\u001b[1;31mKeyError\u001b[0m: tensor(18)"
     ]
    }
   ],
   "source": [
    "#Encode the input text and store it into a Torch Tensor\n",
    "#A tensor is a multi-dimensional matrix containing elements of a single data type\n",
    "\n",
    "#Convert the text to numbers\n",
    "encodedText = encode(text)\n",
    "print(\"Length of encoded text: \", len(encodedText))\n",
    "\n",
    "#Convert the list to a tensor\n",
    "data = torch.tensor(encodedText, dtype=torch.long)\n",
    "print(data.shape)\n",
    "print(data[:10]) #First 10 elements (First 10 characters in the text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data:  1115394\n",
      "Length of training data:  1003854\n",
      "Length of validation data:  111540\n"
     ]
    }
   ],
   "source": [
    "#Get Training and Validation Data\n",
    "#We will use the first 90% of the data for training and the last 10% for validation\n",
    "\n",
    "#Get the length of the data\n",
    "dataLen = len(data)\n",
    "print(\"Length of data: \", dataLen)\n",
    "\n",
    "#Get the length of the training data  \n",
    "trainLen = int(dataLen * 0.9)\n",
    "\n",
    "#Get the training data\n",
    "train_data = data[:trainLen]\n",
    "print(\"Length of training data: \", len(train_data))\n",
    "\n",
    "#Get the validation data\n",
    "val_data = data[trainLen:]  \n",
    "print(\"Length of validation data: \", len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence:  tensor([18, 47, 56, 57, 58,  1, 15, 47])\n",
      "Output sequence:  tensor([47, 56, 57, 58,  1, 15, 47, 58])\n",
      "1 : Context:  tensor([18])  Target:  tensor(47)\n",
      "2 : Context:  tensor([18, 47])  Target:  tensor(56)\n",
      "3 : Context:  tensor([18, 47, 56])  Target:  tensor(57)\n",
      "4 : Context:  tensor([18, 47, 56, 57])  Target:  tensor(58)\n",
      "5 : Context:  tensor([18, 47, 56, 57, 58])  Target:  tensor(1)\n",
      "6 : Context:  tensor([18, 47, 56, 57, 58,  1])  Target:  tensor(15)\n",
      "7 : Context:  tensor([18, 47, 56, 57, 58,  1, 15])  Target:  tensor(47)\n",
      "8 : Context:  tensor([18, 47, 56, 57, 58,  1, 15, 47])  Target:  tensor(58)\n"
     ]
    }
   ],
   "source": [
    "block_size = 8 #The length of the sequence we want to train on (the context)\n",
    "#Example: If block_size = 8, then we want to predict the 9th character in the sequence\n",
    "#This is why we will need to train the model on sequences of length block_size + 1\n",
    "#In the below code the max value of t+1 is block_size\n",
    "\n",
    "x = train_data[0:block_size] # The input sequence\n",
    "y = train_data[1:block_size+1] # The output sequence\n",
    "\n",
    "print(\"Input sequence: \", x)\n",
    "print(\"Output sequence: \", y)\n",
    "\n",
    "for t in range(block_size): \n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(t+1, ': Context: ', str(context), ' Target: ', str(target)) \n",
    "    #Ex. If data is {1,2,3} and we are given 1, then the target (predicted output) should be 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape:  torch.Size([4, 8])\n",
      "Output batch shape:  torch.Size([4, 8])\n",
      "-----------------\n",
      "Input batch: \n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "-----------------\n",
      "Output batch: \n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "-----------------\n",
      "1 : Context:  tensor([[24],\n",
      "        [44],\n",
      "        [52],\n",
      "        [25]])  \n",
      "Target:  tensor([43, 53, 58, 17])\n",
      "2 : Context:  tensor([[24, 43],\n",
      "        [44, 53],\n",
      "        [52, 58],\n",
      "        [25, 17]])  \n",
      "Target:  tensor([58, 56,  1, 27])\n",
      "3 : Context:  tensor([[24, 43, 58],\n",
      "        [44, 53, 56],\n",
      "        [52, 58,  1],\n",
      "        [25, 17, 27]])  \n",
      "Target:  tensor([ 5,  1, 58, 10])\n",
      "4 : Context:  tensor([[24, 43, 58,  5],\n",
      "        [44, 53, 56,  1],\n",
      "        [52, 58,  1, 58],\n",
      "        [25, 17, 27, 10]])  \n",
      "Target:  tensor([57, 58, 46,  0])\n",
      "5 : Context:  tensor([[24, 43, 58,  5, 57],\n",
      "        [44, 53, 56,  1, 58],\n",
      "        [52, 58,  1, 58, 46],\n",
      "        [25, 17, 27, 10,  0]])  \n",
      "Target:  tensor([ 1, 46, 39, 21])\n",
      "6 : Context:  tensor([[24, 43, 58,  5, 57,  1],\n",
      "        [44, 53, 56,  1, 58, 46],\n",
      "        [52, 58,  1, 58, 46, 39],\n",
      "        [25, 17, 27, 10,  0, 21]])  \n",
      "Target:  tensor([46, 39, 58,  1])\n",
      "7 : Context:  tensor([[24, 43, 58,  5, 57,  1, 46],\n",
      "        [44, 53, 56,  1, 58, 46, 39],\n",
      "        [52, 58,  1, 58, 46, 39, 58],\n",
      "        [25, 17, 27, 10,  0, 21,  1]])  \n",
      "Target:  tensor([43, 58,  1, 54])\n",
      "8 : Context:  tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])  \n",
      "Target:  tensor([39,  1, 46, 39])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337) #Set the seed for reproducibility\n",
    "block_size = 8 #The length of the sequence we want to train on \n",
    "batch_size = 4 #The number of sequences we want to train on at a time\n",
    "\n",
    "def get_batch(split):\n",
    "    #Get the data depending on the split (train or validation)\n",
    "    if split == 'train':\n",
    "        data = train_data\n",
    "    else:\n",
    "        data = val_data\n",
    "    \n",
    "    #Get batch_size random starting indexes\n",
    "    ix = torch.randint(high=len(data)-block_size, size=(batch_size,))\n",
    "\n",
    "    #Construct the input and output sequences\n",
    "    x = [data[i:i+block_size] for i in ix]\n",
    "    y = [data[i+1:i+block_size+1] for i in ix]\n",
    "    \n",
    "    #Convert the sequences to tensors of size (batch_size, block_size)\n",
    "    x = torch.stack(x)\n",
    "    y = torch.stack(y)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "#Test\n",
    "xb, yb = get_batch('train')\n",
    "print(\"Input batch shape: \", xb.shape)\n",
    "print(\"Output batch shape: \", yb.shape)\n",
    "\n",
    "print(\"-----------------\")\n",
    "print(\"Input batch: \")\n",
    "print(xb)\n",
    "print(\"-----------------\")\n",
    "print(\"Output batch: \")\n",
    "print(yb)\n",
    "print(\"-----------------\")\n",
    "\n",
    "for t in range(block_size): #Basically the same as the previous but now we are using batches (multiple sequences)\n",
    "    context = xb[:, :t+1] #Get the first t+1 elements of each sequence\n",
    "    target = yb[:, t]\n",
    "    print(t+1, ': Context: ', str(context), ' \\nTarget: ', str(target)) \n",
    "    #Ex. If data is {1,2,3} and we are given 1, then the target (predicted output) should be 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bL?DP-QWkrEoL?jLDJQcLVf'RIHD'Hdhs Yv,ixa,jswYZwLEuS'paokqOzs$!A$zFGQT;eMk x.gQ$FCLg!iWn.O!zDGyA YsT3\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        #super() returns the parent object of the class\n",
    "        #In this case, it returns the parent object of BigramLanguageModel which is nn.Module (defined above)\n",
    "        super().__init__() # Call the parent class constructor\n",
    "\n",
    "        \n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size) #Embedding layer\n",
    "        #Embedding layer is used to convert the input tokens to vectors of size embedding_dim\n",
    "        #In this case, the input tokens are numbers (the encoded text) and the embedding_dim is vocab_size\n",
    "        #Vectors will allow us to do math operations on the tokens\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        logits = self.token_embedding_table(idx)*.1 #Get the embeddings for the input tokens. (Batch, Time, Channel) or (Batch, Block_size, vocab_size)\n",
    "        if targets != None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.shape[-1]), targets.view(-1)) #Calculate the loss. Logits and targets need to be reshaped to (Batch * Block_size, vocab_size) and (Batch * Block_size) respectively\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "        return logits,loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits,loss = self(idx)\n",
    "            probs = F.softmax((logits[:, -1]), dim=-1)\n",
    "            new_token = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, new_token), dim=-1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(len(chars)) #Create the model\n",
    "out,loss = m(xb, yb) #Get the output\n",
    "\n",
    "#Test Generate\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "out = ((m.generate(idx, 100).squeeze().tolist()))\n",
    "print(decode(out))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pytorch optimizer\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 , Loss:  2.6501591205596924\n",
      "Step:  1000 , Loss:  2.6225929260253906\n",
      "Step:  2000 , Loss:  2.5740420818328857\n",
      "Step:  3000 , Loss:  2.6518807411193848\n",
      "Step:  4000 , Loss:  2.53884220123291\n",
      "Step:  5000 , Loss:  2.667741298675537\n",
      "Step:  6000 , Loss:  2.56286358833313\n",
      "Step:  7000 , Loss:  2.527754306793213\n",
      "Step:  8000 , Loss:  2.60963773727417\n",
      "Step:  9000 , Loss:  2.5388073921203613\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000): \n",
    "    #Get the input an0d output sequences\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    #Get the logits and loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    \n",
    "    #Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Backpropagate the loss\n",
    "    loss.backward()\n",
    "    \n",
    "    #Update the parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    #Print the loss every 10 steps\n",
    "    if steps % 1000 == 0:\n",
    "        print(\"Step: \", steps, \", Loss: \", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Owhowee:\n",
      "\n",
      " chatwaishovzKBobrem,Pr\n",
      "ymqPamoure:haisoue cear ve\n",
      "vo llillil'Tblmead mpYvJall,ony btlwd w\n"
     ]
    }
   ],
   "source": [
    "#Test Generate\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "out = ((m.generate(idx, 100).squeeze().tolist()))\n",
    "print(decode(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
